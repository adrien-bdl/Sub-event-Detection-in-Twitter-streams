{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_main_kernel(word_vectors, axis=0, n_clusters=3):\n",
    "    \"get the vector of the center of the kernel\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(word_vectors)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    largest_cluster_label = np.bincount(labels).argmax()\n",
    "    largest_cluster_indices = np.where(labels == largest_cluster_label)[0]\n",
    "    largest_cluster_vectors = word_vectors[largest_cluster_indices]\n",
    "    largest_cluster_centroid = largest_cluster_vectors.mean(axis=0)\n",
    "\n",
    "    return largest_cluster_centroid\n",
    "\n",
    "\n",
    "# Function to compute the average word vector for a tweet\n",
    "def get_avg_embedding(tweet, model, vector_size=200):\n",
    "    tweet = str(tweet)\n",
    "    words = tweet.split()  # Tokenize by whitespace\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if (\n",
    "        not word_vectors\n",
    "    ):  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "def get_main_kernel_embedding(df, n_clusters=3):\n",
    "    if \"EventType\" in df.columns:\n",
    "        vector_columns = [\"EventType\"] + [str(i) for i in range(200)]\n",
    "    else:\n",
    "        vector_columns = [str(i) for i in range(200)]\n",
    "\n",
    "    df[vector_columns] = (\n",
    "        df[vector_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    )\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(df[vector_columns])\n",
    "\n",
    "    # Store cluster labels in a separate DataFrame\n",
    "    clusters_df = pd.DataFrame(kmeans.labels_, columns=[\"cluster\"], index=df.index)\n",
    "\n",
    "    # Concatenate cluster labels with the original DataFrame\n",
    "    df = pd.concat([df, clusters_df], axis=1)\n",
    "\n",
    "    main_kernel_label = df[\"cluster\"].value_counts().idxmax()\n",
    "    df[\"is_main_kernel\"] = (df[\"cluster\"] == main_kernel_label).astype(int)\n",
    "    main_kernel_vectors = df[df[\"cluster\"] == main_kernel_label][vector_columns]\n",
    "    avg_main_kernel_embedding = main_kernel_vectors.mean(axis=0)\n",
    "\n",
    "    return avg_main_kernel_embedding, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Charles/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Charles/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### DOWNLOAD MODEL\n",
    "\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "\n",
    "# Download some NLP models for processing, optional\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "# Load GloVe model with Gensim's API\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOAD TRAIN DATASET TO ADD FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArgentinaBelgium72.csv\n",
      "ArgentinaGermanyFinal77.csv\n",
      "AustraliaNetherlands29.csv\n",
      "AustraliaSpain34.csv\n",
      "BelgiumSouthKorea59.csv\n",
      "CameroonBrazil36.csv\n",
      "FranceGermany70.csv\n",
      "FranceNigeria66.csv\n",
      "GermanyAlgeria67.csv\n",
      "GermanyBrazil74.csv\n",
      "GermanyUSA57.csv\n",
      "HondurasSwitzerland54.csv\n",
      "MexicoCroatia37.csv\n",
      "NetherlandsChile35.csv\n",
      "PortugalGhana58.csv\n",
      "USASlovenia2010.csv\n",
      "\n",
      " Testing data shape: (5056050, 6)\n"
     ]
    }
   ],
   "source": [
    "path_data = \"../challenge_data/train_tweets\"\n",
    "\n",
    "files = []\n",
    "\n",
    "for i, filename in enumerate(os.listdir(path_data)):\n",
    "    if filename == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = pd.read_csv(f\"{path_data}/\" + filename)\n",
    "\n",
    "    files.append(df)\n",
    "\n",
    "df = pd.concat(files, ignore_index=True)\n",
    "print(\"\\n\", f\"Testing data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATION AUTRES FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les tweets avec plus de 3 lettres identiques consécutives\n",
    "regex = r\"(.)\\1{2,}\"  # Cherche des séquences de 3 caractères identiques ou plus\n",
    "df[\"Has_Repeated_Letters\"] = df[\"Tweet\"].apply(lambda x: bool(re.search(regex, x)))\n",
    "\n",
    "# Expression régulière pour détecter les émojis\n",
    "emoji_regex = r\"[\\U00010000-\\U0010ffff]\"\n",
    "df[\"Emoji_Count\"] = df[\"Tweet\"].apply(lambda x: len(re.findall(emoji_regex, x)))\n",
    "\n",
    "# Compter le nombre de points d'exclamation et d'interrogation\n",
    "df[\"Exclamation_Count\"] = df[\"Tweet\"].apply(lambda x: x.count(\"!\"))\n",
    "df[\"Question_Count\"] = df[\"Tweet\"].apply(lambda x: x.count(\"?\"))\n",
    "\n",
    "# Intermediate features\n",
    "df[\"starts_with_RT\"] = df[\"Tweet\"].str.startswith(\n",
    "    \"RT\"\n",
    ")  # ne jamais les mettre après aggrégation\n",
    "df[\"isMention\"] = df[\"Tweet\"].apply(\n",
    "    lambda x: \"@\" in x\n",
    ")  # ne jamais les metter après aggrégation\n",
    "\n",
    "### ADD FEATURES\n",
    "\n",
    "df[\"nb_tweets_per_minute\"] = df.groupby(by=[\"ID\"])[\"ID\"].transform(\"count\")\n",
    "df[\"nb_consecutive_letters_per_minute\"] = df.groupby(by=[\"ID\"])[\n",
    "    \"Has_Repeated_Letters\"\n",
    "].transform(\"count\")\n",
    "df[\"nb_smileys_per_minute\"] = df.groupby(by=[\"ID\"])[\"Emoji_Count\"].transform(\"count\")\n",
    "df[\"Exclamation_Count_per_minute\"] = df.groupby(by=[\"ID\"])[\n",
    "    \"Exclamation_Count\"\n",
    "].transform(\"count\")\n",
    "df[\"Question_Count_per_minute\"] = df.groupby(by=[\"ID\"])[\"Question_Count\"].transform(\n",
    "    \"count\"\n",
    ")\n",
    "df[\"nb_RT_per_min\"] = df.groupby(\"ID\")[\"starts_with_RT\"].transform(\"sum\")\n",
    "df[\"nb_@_per_min\"] = df.groupby(\"ID\")[\"isMention\"].transform(\"sum\")\n",
    "df[\"Match_time\"] = df[\"ID\"].str.split(\"_\").str[1].astype(int)\n",
    "\n",
    "\n",
    "df_new_features = df.drop_duplicates(subset=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ EMBEDDING + CONCATENATE WITH NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ the already computed embeddings\n",
    "li = []\n",
    "for filename in os.listdir(\"kernel_with_model_teacher/dataframe_with_kernel_embedding\"):\n",
    "    imported_df = pd.read_csv(\n",
    "        \"kernel_with_model_teacher/dataframe_with_kernel_embedding/\" + filename\n",
    "    )\n",
    "    li.append(imported_df)\n",
    "imported_df = pd.concat(li, ignore_index=True)\n",
    "\n",
    "### Merge with new features in df_new_features\n",
    "imported_df[\"ID\"] = imported_df[\"ID\"].astype(str)\n",
    "df_new_features[\"ID\"] = df_new_features[\"ID\"].astype(str)\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"nb_tweets_per_minute\",\n",
    "    \"nb_RT_per_min\",\n",
    "    \"nb_@_per_min\",\n",
    "    \"Match_time\",\n",
    "    \"nb_consecutive_letters_per_minute\",\n",
    "    \"nb_smileys_per_minute\",\n",
    "    \"Exclamation_Count_per_minute\",\n",
    "    \"Question_Count_per_minute\",\n",
    "]\n",
    "period_features = pd.concat(\n",
    "    [imported_df.set_index(\"ID\"), df_new_features.set_index(\"ID\")[columns_to_keep]],\n",
    "    axis=1,\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATION df_X and df_y pour le training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_features_to_drop = [\"MatchID\", \"ID\", \"Match_time\"]\n",
    "\n",
    "df_X = period_features.drop(columns=liste_features_to_drop + [\"EventType\"])\n",
    "df_y = period_features[\"EventType\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA terminée, DataFrame final créé avec 50 nouvelles features.\n"
     ]
    }
   ],
   "source": [
    "# Sélection des colonnes pour la PCA\n",
    "columns_to_pca = [str(i) for i in range(1, 200)]  # Colonnes '1' à '199'\n",
    "X_pca_input = df_X[columns_to_pca]\n",
    "\n",
    "# number of Principal Components\n",
    "N = 50\n",
    "\n",
    "pca = PCA(n_components=N)  # Réduction à N features\n",
    "X_pca = pca.fit_transform(X_pca_input)\n",
    "\n",
    "pca_columns = [f\"PCA_{i+1}\" for i in range(N)]\n",
    "df_pca = pd.DataFrame(X_pca, columns=pca_columns, index=df_X.index)\n",
    "\n",
    "columns_to_keep = [col for col in df_X.columns if col not in columns_to_pca]\n",
    "df_final = pd.concat([df_X[columns_to_keep], df_pca], axis=1)\n",
    "\n",
    "# Résultat\n",
    "print(f\"PCA terminée, DataFrame final créé avec {N} nouvelles features.\")\n",
    "\n",
    "df_X = df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MODELS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Meilleurs paramètres trouvés : {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Meilleure précision moyenne (cross-validation) : 0.569517827048086\n",
      "Random Forest - Accuracy moyenne (cross-validation) avec Grid Search : 0.5546728971962618\n",
      "Random Forest - Ecart-type de l'Accuracy (cross-validation) avec Grid Search : 0.11025043947982338\n"
     ]
    }
   ],
   "source": [
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],  # Nombre d'arbres dans la forêt\n",
    "    \"max_depth\": [10, 20],  # Profondeur maximale des arbres\n",
    "    \"min_samples_split\": [\n",
    "        2,\n",
    "        5,\n",
    "    ],  # Nombre minimal d'échantillons nécessaires pour diviser un nœud\n",
    "    \"min_samples_leaf\": [\n",
    "        2,\n",
    "        4,\n",
    "    ],  # Nombre minimal d'échantillons nécessaires dans un feuille\n",
    "    \"max_features\": [\n",
    "        \"auto\",\n",
    "        \"sqrt\",\n",
    "        \"log2\",\n",
    "    ],  # Nombre de caractéristiques à considérer pour la division\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision moyenne (cross-validation) :\", grid_search.best_score_)\n",
    "\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "\n",
    "rf_cv_scores = cross_val_score(best_rf_clf, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\n",
    "    \"Random Forest - Accuracy moyenne (cross-validation) avec Grid Search :\",\n",
    "    np.mean(rf_cv_scores),\n",
    ")\n",
    "print(\n",
    "    \"Random Forest - Ecart-type de l'Accuracy (cross-validation) avec Grid Search :\",\n",
    "    np.std(rf_cv_scores),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Meilleurs paramètres trouvés : {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Meilleure précision moyenne (cross-validation) : 0.599463765895511\n"
     ]
    }
   ],
   "source": [
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=50)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [3, 4],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"subsample\": [1.0],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision moyenne (cross-validation) :\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_gb_clf = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "gb_cv_scores = cross_val_score(best_gb_clf, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\n",
    "    \"Gradient Boosting - Accuracy moyenne (cross-validation) avec Grid Search :\",\n",
    "    np.mean(gb_cv_scores),\n",
    ")\n",
    "print(\n",
    "    \"Gradient Boosting - Ecart-type de l'Accuracy (cross-validation) avec Grid Search :\",\n",
    "    np.std(gb_cv_scores),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Meilleurs paramètres : {'C': 0.1, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Meilleure accuracy (cross-validation) : 0.6368830571910088\n",
      "Standard deviation : 0.052929487676251316\n"
     ]
    }
   ],
   "source": [
    "X = df_X\n",
    "y = df_y\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"saga\"],\n",
    "    \"max_iter\": [5000],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleure accuracy (cross-validation) :\", grid_search.best_score_)\n",
    "# Écart-type pour les meilleurs paramètres\n",
    "best_index = grid_search.best_index_\n",
    "best_std = grid_search.cv_results_[\"std_test_score\"][best_index]\n",
    "print(\"Standard deviation :\", best_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X = df_X\n",
    "# y = df_y\n",
    "\n",
    "# mandatory_columns = [\"PCA_\" + str(i) for i in range(1, N + 1)]  # PC 1 to N + 1\n",
    "# optional_columns = [col for col in X.columns if col not in mandatory_columns]\n",
    "\n",
    "# num_combinations = 10\n",
    "\n",
    "\n",
    "# def evaluate_combination(subset):\n",
    "#     selected_columns = list(subset)\n",
    "#     X_subset = X[mandatory_columns + selected_columns]\n",
    "\n",
    "#     model = LogisticRegression(max_iter=10_000)\n",
    "\n",
    "#     scores = cross_val_score(model, X_subset, y, cv=5, scoring=\"accuracy\")\n",
    "#     return subset, scores.mean()\n",
    "\n",
    "\n",
    "# random_combinations = []\n",
    "# for _ in range(num_combinations):\n",
    "#     subset_size = random.randint(1, len(optional_columns))\n",
    "#     subset = random.sample(optional_columns, subset_size)\n",
    "#     random_combinations.append(subset)\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(\n",
    "#     delayed(evaluate_combination)(subset) for subset in tqdm(random_combinations)\n",
    "# )\n",
    "\n",
    "# results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print(\"Top 5 combinaisons de features avec leur précision moyenne :\")\n",
    "# for subset, score in results[:5]:  # Top 5 combinaisons\n",
    "#     selected_columns = list(subset)\n",
    "#     print(f\"Features: {selected_columns}, Mean Accuracy: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy moyenne (cross-validation) : 0.603142988465495\n",
      "Accuracy std (cross-validation) : 0.06513938204080033\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION SUR TOUTE LA DATA + TOUTES LES FEATURES\n",
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=10_000)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    clf, X, y, cv=5, scoring=\"accuracy\"\n",
    ")  # 5-fold cross-validation\n",
    "\n",
    "print(\"Accuracy moyenne (cross-validation) :\", np.mean(cv_scores))\n",
    "print(\"Accuracy std (cross-validation) :\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Meilleurs paramètres trouvés : {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Meilleure précision moyenne (cross-validation) : 0.5975913239510604\n",
      "XGBoost - Accuracy moyenne (cross-validation) avec Grid Search : 0.5583980518625774\n",
      "XGBoost - Ecart-type de l'Accuracy (cross-validation) avec Grid Search : 0.09414449374914556\n"
     ]
    }
   ],
   "source": [
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    random_state=42, n_estimators=100, use_label_encoder=False, eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],  # Nombre d'estimateurs (arbres)\n",
    "    \"learning_rate\": [0.1, 0.2],  # Taux d'apprentissage\n",
    "    \"max_depth\": [3, 4],  # Profondeur maximale des arbres\n",
    "    \"min_child_weight\": [1],  # Poids minimal d'un enfant\n",
    "    \"subsample\": [\n",
    "        1.0,\n",
    "    ],  # Fraction d'échantillons utilisée pour entraîner chaque arbre\n",
    "    \"colsample_bytree\": [\n",
    "        0.8,\n",
    "    ],  # Fraction des colonnes utilisées pour chaque arbre\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision moyenne (cross-validation) :\", grid_search.best_score_)\n",
    "\n",
    "best_xgb_clf = grid_search.best_estimator_\n",
    "\n",
    "xgb_cv_scores = cross_val_score(best_xgb_clf, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\n",
    "    \"XGBoost - Accuracy moyenne (cross-validation) avec Grid Search :\",\n",
    "    np.mean(xgb_cv_scores),\n",
    ")\n",
    "print(\n",
    "    \"XGBoost - Ecart-type de l'Accuracy (cross-validation) avec Grid Search :\",\n",
    "    np.std(xgb_cv_scores),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
